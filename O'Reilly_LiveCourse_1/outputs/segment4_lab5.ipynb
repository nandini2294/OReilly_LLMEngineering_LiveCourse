{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae2b3a2-02d4-4061-9639-3a6f09810a44",
   "metadata": {},
   "source": [
    "# Segment 4 Lab 5\n",
    "\n",
    "Introducing a critical agent - the agent that brings it all together.\n",
    "\n",
    "# Planning Agent\n",
    "\n",
    "There are a number of frameworks out there that support building Agentic Workflows.\n",
    "\n",
    "OpenAI has Swarm, LangChain has LangGraph, Gradio and HuggingFace have offerings, and there's Autogen from Microsoft, Crew.ai and many others.  \n",
    "\n",
    "Each of these are abstractions on top of APIs to LLMs; some are lightweight, others come with significant functionality.\n",
    "\n",
    "It's also perfectly possible - and sometimes considerably easier - to build an agentic solution by calling LLMs directly.\n",
    "\n",
    "There's been considerable convergence on LLM APIs, and it's not clear that there's a need to sign up for one of the agent ecosystems for many use cases.\n",
    "\n",
    "Anthropic has an [insightful post](https://www.anthropic.com/research/building-effective-agents) on building effective Agentic architectures that's well worth a read.\n",
    "\n",
    "## Using Tools to give our Agent autonomy\n",
    "\n",
    "In our case, we're going to create an Agent that uses Tools to make decisions about what to do next.\n",
    "\n",
    "This is a bit over the top for this simple example, because we know exactly what the Agent is supposed to do. But it allows us to give the Agent some freedom..\n",
    "\n",
    "Let's see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f171c2b-1943-43a5-85c6-0bcd84bdd3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612c8116-e4b6-4332-8bdb-d7c90b4aa9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0896c5f3-1ecc-4464-b913-2e7cfe29c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Scanner agent from before\n",
    "\n",
    "from agents.scanner_agent import ScannerAgent\n",
    "scanner = ScannerAgent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f25eed-e48a-4f9a-9817-4c0451378b40",
   "metadata": {},
   "source": [
    "# Our tools\n",
    "\n",
    "The next 3 cells have 3 **fake** functions that we will allow our LLM to call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f920a35-c58d-4961-8c3c-40d70157da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_the_internet_for_bargains():\n",
    "    print(f\"Scanning the internet\")\n",
    "    results = scanner.test_scan()\n",
    "    return results.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f885983-e054-43f3-86b4-6db9323216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_true_value(description: str) -> str:\n",
    "    print(f\"Estimating true value of {description[:20]}...\")\n",
    "    return {\"description\": description, \"estimated_true_value\": 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a42f55-0f75-44b1-830f-ee13d161cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def notify_user_of_deal(description: str, deal_price: float, estimated_true_value: float):\n",
    "    print(f\"Notifying user of {description} which costs {deal_price} and estimate is {estimated_true_value}\")\n",
    "    return {\"notification_sent\": \"ok\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dd672-e77e-4f91-a66d-fe67f10ac093",
   "metadata": {},
   "source": [
    "## Telling the LLM about the tools it can use, with JSON\n",
    "\n",
    "\"Tool calling\" is giving an LLM the power to run code on your computer!\n",
    "\n",
    "Sounds a bit spooky?\n",
    "\n",
    "The way it works is a little more mundane. We give the LLM a description of each Tool and the parameters, and we let it inform us if it wants any tool to be run.\n",
    "\n",
    "It's not like OpenAI reaches in and runs a function. In the end, we have an if statement that calls our function if the model requests it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb4a0727-d971-44bb-9c90-59f9e1323261",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_function = {\n",
    "    \"name\": \"scan_the_internet_for_bargains\",\n",
    "    \"description\": \"Returns top bargains scraped from the internet along with the price each item is being offered for\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {},\n",
    "        \"required\": [],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4c9cea-fd6f-45ac-b8fe-cc15722ec231",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_function = {\n",
    "    \"name\": \"estimate_true_value\",\n",
    "    \"description\": \"Given the description of an item, estimate how much it is actually worth\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of the item to be estimated\"\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"description\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b863aa-b86b-45db-8ac0-0fe6fb101284",
   "metadata": {},
   "outputs": [],
   "source": [
    "notify_function = {\n",
    "    \"name\": \"notify_user_of_deal\",\n",
    "    \"description\": \"Send the user a push notification about the most compelling deal\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The description of the item\"\n",
    "            },\n",
    "            \"deal_price\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The price offered by this deal scraped from the internet\"\n",
    "            }\n",
    "            ,\n",
    "            \"estimated_true_value\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The estimated actual value that this is worth\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"description\", \"deal_price\", \"estimated_true_value\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54c1d76a-8744-46d0-afb3-d881820d876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\"type\": \"function\", \"function\": scan_function},\n",
    "        {\"type\": \"function\", \"function\": estimate_function},\n",
    "        {\"type\": \"function\", \"function\": notify_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088a008-fed8-4bc6-8041-8801adb3754c",
   "metadata": {},
   "source": [
    "## And now to bring it together - Tool calling in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "018b825e-df74-412f-a829-2a4c92cf1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"scan_the_internet_for_bargains\": scan_the_internet_for_bargains, \"estimate_true_value\": estimate_true_value, \"notify_user_of_deal\": notify_user_of_deal}\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    results = []\n",
    "    for tool_call in message.tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        print(f\"Tool called: {tool_name}\", flush=True)\n",
    "        tool = mapping.get(tool_name)\n",
    "        result = tool(**arguments) if tool else {}\n",
    "        results.append({\"role\": \"tool\",\"content\": json.dumps(result),\"tool_call_id\": tool_call.id})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d195e6ad-c838-4a5f-ab3c-f3cb7f470fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an Autonomous AI Agent that makes use of tools to carry out your mission. Your mission is to find great deals on bargain products, and notify the user when you find them.\"\n",
    "user_message = \"Your mission is to discover great deals on products. First you should scan the internet for bargain deals. Then for each deal, you should estimate its true value - how much it's actually worth. \"\n",
    "user_message += \"Finally, you should pick the single most compelling deal where the deal price is much lower than the estimated true value, and send the user a push notification about that deal. \"\n",
    "user_message += \"You must only notify the user about one deal, and be sure to pick the most compelling deal, where the deal price is much lower than the estimated true value. Then just respond OK to indicate success.\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},{\"role\": \"user\", \"content\": user_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3021830-b216-4013-8456-671a370f4450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called: scan_the_internet_for_bargains\n",
      "Scanning the internet\n",
      "Tool called: estimate_true_value\n",
      "Estimating true value of The Hisense R6 Serie...\n",
      "Tool called: estimate_true_value\n",
      "Estimating true value of The Poly Studio P21 ...\n",
      "Tool called: estimate_true_value\n",
      "Estimating true value of The Lenovo IdeaPad S...\n",
      "Tool called: estimate_true_value\n",
      "Estimating true value of The Dell G15 gaming ...\n",
      "Tool called: estimate_true_value\n",
      "Estimating true value of The certified refurb...\n",
      "Tool called: notify_user_of_deal\n",
      "Notifying user of The Hisense R6 Series 55R6030N is a 55-inch 4K UHD Roku Smart TV that offers stunning picture quality with 3840x2160 resolution. It features Dolby Vision HDR and HDR10 compatibility, ensuring a vibrant and dynamic viewing experience. The TV runs on Roku's operating system, allowing easy access to streaming services and voice control compatibility with Google Assistant and Alexa. With three HDMI ports available, connecting multiple devices is simple and efficient. which costs 178 and estimate is 300\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# A loop that repeatedly calls gpt-4o-mini until it has no more tools to call\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        results = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.extend(results)\n",
    "    else:\n",
    "        done = True\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67020429-93a3-4c26-b4ae-7c9c9f1d41a2",
   "metadata": {},
   "source": [
    "## And now - putting all of this into a Planning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30b1875-3a42-41c0-b217-9789090347b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.autonomous_planning_agent import AutonomousPlanningAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "767db7b9-8d78-4d02-9b79-6c5e2dd8ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "root = logging.getLogger()\n",
    "root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83fbf6c0-301e-4da0-b4e3-8f91ab4d686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "DB = \"products_vectorstore\"\n",
    "client = chromadb.PersistentClient(path=DB)\n",
    "collection = client.get_or_create_collection('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "208067d9-8396-4f95-8dc8-a614c9a455df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Initializing Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is set up with DeepSeek-R1 via Groq\u001b[0m\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is initializing\u001b[0m\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "/Users/ed/miniconda3/envs/tech2ai/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/ed/miniconda3/envs/tech2ai/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator RandomForestRegressor from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is ready\u001b[0m\n",
      "/Users/ed/miniconda3/envs/tech2ai/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent is ready\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[37m[Messaging Agent] Messaging Agent is initializing\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[37m[Messaging Agent] Messaging Agent has initialized Pushover and Claude\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "agent = AutonomousPlanningAgent(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0121edc8-c309-4d04-b737-16a4235a83fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is kicking off a run\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is calling scanner\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is about to fetch deals from RSS feed\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 15 deals not already scraped\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is calling OpenAI using Structured Output\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[36m[Scanner Agent] Scanner Agent received 5 selected deals with price>0 from OpenAI\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value via Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Running Ensemble Agent - collaborating with specialist, frontier and random forest agents\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $25.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d35a0535170a4112bc7397551fc7ff54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is about to call deepseek-r1-distill-llama-70b with RAG context of 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent completed - predicting $39.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is starting a prediction\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c374c5afeb147a486b7aa597651b825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent completed - predicting $174.65\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent complete - returning $48.38\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value via Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Running Ensemble Agent - collaborating with specialist, frontier and random forest agents\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $90.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1751aecd9ae3481888eb23d3976787ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is about to call deepseek-r1-distill-llama-70b with RAG context of 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent completed - predicting $69.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is starting a prediction\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5633bed754524a0b9d2fd894b315cb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent completed - predicting $280.59\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent complete - returning $91.26\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value via Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Running Ensemble Agent - collaborating with specialist, frontier and random forest agents\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $50.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a2af86166f498cb6f3d93070fd6ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is about to call deepseek-r1-distill-llama-70b with RAG context of 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent completed - predicting $99.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is starting a prediction\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc1939e12af439e91074a00d2000e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent completed - predicting $216.59\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent complete - returning $72.97\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value via Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Running Ensemble Agent - collaborating with specialist, frontier and random forest agents\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $110.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24575d46d0004a9c93c41cfe6e44ed67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is about to call deepseek-r1-distill-llama-70b with RAG context of 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent completed - predicting $99.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is starting a prediction\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e2ab9d247e460bb8631e7619c3f2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent completed - predicting $211.54\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent complete - returning $123.41\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is estimating value via Ensemble Agent\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Running Ensemble Agent - collaborating with specialist, frontier and random forest agents\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is calling remote fine-tuned model\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[31m[Specialist Agent] Specialist Agent completed - predicting $950.00\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is using Llama 3.2 to preprocess the description\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is vectorizing using all-MiniLM-L6-v2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a78f8a89dd419aa9685d1b66b8d323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is performing a RAG search of the Chroma datastore to find 5 similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent has found similar products\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is about to call deepseek-r1-distill-llama-70b with RAG context of 5 similar products\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[34m[Frontier Agent] Frontier Agent completed - predicting $1099.99\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is starting a prediction\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee539edf1fd418d8bdd9b6ca50e624f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent completed - predicting $376.65\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[33m[Ensemble Agent] Ensemble Agent complete - returning $1015.33\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning agent is notifying user\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[37m[Messaging Agent] Messaging Agent is using Claude to craft the message\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[37m[Messaging Agent] Messaging Agent is sending a push notification\u001b[0m\n",
      "INFO:root:\u001b[40m\u001b[37m[Messaging Agent] Messaging Agent has completed\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:\u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent completed with: OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = agent.plan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e15e5-dddc-4f2e-bbb4-ab9a5392eca7",
   "metadata": {},
   "source": [
    "# Finally - with a Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6f9da59-43c4-409f-8a93-5993e1d9e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset memory back to 2 deals discovered in the past\n",
    "\n",
    "from deal_agent_framework import DealAgentFramework\n",
    "DealAgentFramework.reset_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805095ad-9d07-4869-9432-338f87fb65ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Initializing Agent Framework\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[44m\u001b[37m[Agent Framework] Initializing Agent Framework\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[32m[Autonomous Planning Agent] Autonomous Planning Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[36m[Scanner Agent] Scanner Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[33m[Ensemble Agent] Initializing Ensemble Agent\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[33m[Ensemble Agent] Initializing Ensemble Agent\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is initializing - connecting to modal\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[31m[Specialist Agent] Specialist Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Initializing Frontier Agent\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is set up with DeepSeek-R1 via Groq\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is set up with DeepSeek-R1 via Groq\u001b[0m\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-03-04 22:22:46 -0500] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] \u001b[40m\u001b[34m[Frontier Agent] Frontier Agent is ready\u001b[0m\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] \u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] \u001b[40m\u001b[35m[Random Forest Agent] Random Forest Agent is initializing\u001b[0m\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] Use pytorch device_name: mps\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "[2025-03-04 22:22:47 -0500] [Agents] [INFO] Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "/Users/ed/miniconda3/envs/tech2ai/lib/python3.11/site-packages/sklearn/base.py:380: InconsistentVersionWarning:\n",
      "\n",
      "Trying to unpickle estimator DecisionTreeRegressor from version 1.5.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python price_is_right.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df197f7-7ed4-4b24-a333-80ffda9d7032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
